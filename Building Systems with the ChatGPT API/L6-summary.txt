
Moderation API can be used to filter and moderate outputs generated by the system itself. This can be done by providing the generated output as part of the input to the model and asking it to rate the quality of the output. Another approach for checking outputs is to ask the model itself and the generated was satisfactory if it follows a certain rubric.

The model can provide feedback on the quality of a generated output. You can use this feedback to decide whether to present the output to the user or to generate a new response. You could even experiment with generating multiple model responses per user query.